{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamaramrt/Mamo.ia/blob/main/Explica%C3%A7%C3%A3o_Extra%C3%A7%C3%A3o_de_atributos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLqCoWbWuieh"
      },
      "source": [
        "\n",
        "\n",
        "### 1. **IDEIA GERAL:**\n",
        "\n",
        " A ideia geral do codigo é receber como entrada uma imagem e ter como saída o vetor dos atributos extraídos daquela imagem.\n",
        "\n",
        " Para isso, ele vai utilizar uma rede neural convolucional, a Lenet (a mesma rede neural utilizada no weka). Essa Lenet será treinada em um conjunto de dados de imagens, chamamos de dataset, que é o CIFAR-100. Ele possui imagens coloridas e 100 categorias diferentes.\n",
        "\n",
        " Só explicando melhor, a rede neural convolucional vai processar imagens para aprender padroes e daí extrair os atributos, que serão as \"informações relevantes\".\n",
        "\n",
        "\n",
        "### 2. **PASSOS DO CODIGO:**\n",
        "\n",
        "*   Treinar a Lenet no CIFAR-100\n",
        "*   Extração de atributos com a Lenet Pré-treinada\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hyW2dEExV0n"
      },
      "source": [
        "### **Para fazer esse processo, é importante entender:**\n",
        "\n",
        "- Numpy é uma biblioteca muito comum utilizada para manipulação de arrays;\n",
        "\n",
        "- Pytorch é a biblioteca que vamos usar para a implementação e treinamento da rede neural;\n",
        "\n",
        "- PIL (PILLOW): é a biblioteca utilizada para a gente carregar as imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9QttdIevUroP",
        "outputId": "fbd40131-58a4-4b01-b29c-796650869e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cdr8fmY1T8i2",
        "outputId": "9b7fccf1-e6ac-44d2-a4c8-653cedd10fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p0EjqpfeToO4",
        "outputId": "a9cce815-2a91-4508-fdf4-631b1e711661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.8.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->torchvision) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install liac-arff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SbMUwW-hVYU",
        "outputId": "698b190b-4f98-4f43-b11f-0fdcf77c0455",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=c679f0b7b6ec792ae24fb0319410bd32a79c1767fd0bf55a5e1d1d1d8ef75477\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/ac/cf/c2919807a5c623926d217c0a18eb5b457e5c19d242c3b5963a\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8shaGE7eQ1Hb"
      },
      "source": [
        "## **1. Treinamento da Lenet no CIFAR-100 (dataset disponivel diretamente pela biblioteca Pythorch)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWJY4Q3N2na8"
      },
      "source": [
        "**(aqui acredito que para quem ainda não tem muita experiencia com programação, não precisa se preocupar em entender necessariamente linha por linha do codigo, porque tem alguns conceitos mais avançados. Aconselho vcs focarem em entender o geral do que o código vai fazer e como rodar isso)*.\n",
        "**\n",
        "\n",
        "Dando uma explicação geral, a LeNet é uma rede neural que aprende a reconhecer padroes em imagens.\n",
        "Nesse treinamento, ela passa por:\n",
        "\n",
        "-Camadas convolucionais , são esses conv, conv2 => eles vao identificar as bordas, formas das imagens\n",
        "\n",
        "-fc1, fc2 são as camadas totalmente conectadas, são elas que vão trasnformar as informações em um vetor de atributos\n",
        "\n",
        "-RELU é a função de ativação, ela vai ajudar a rede a aprender padrões mais complexos\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KCZiroW4Bfr"
      },
      "source": [
        "**OBS IMPORTANTE**: Geralmente o treinamento de uma rede neural demora bastante tempo de execução (esse daqui foi mais ou menos 1 hora). Então qnd vcs colocarem para executar e tiver demorando muito, não se preocupem, isso é normal porque a rede vai aprender padrões a partir do CIFAR-100, um conjunto de imagens com 100 classes... Mas cada um precisa colocar para executar porque é a partir desse treinamento que vamos testar a extração de atributos na base de termografia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8T7YkqquBqO"
      },
      "source": [
        "**(obs: salvar o arquivo da Lenet pre treinada na maquina para não precisar treinar novamente )**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os._exit(0)\n",
        "#codigo para reiniciar o runtime caso esteja dando erro na importação do pytorch\n"
      ],
      "metadata": {
        "id": "jBy1L-CbPyJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGmLFGhwqvp4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Definicao da arquitetura da Lenet ajustada para CIFAR-100\n",
        "class LeNetCIFAR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetCIFAR, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)  # primeira camada convolucional para imagens RGB\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #camada de pooling\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5) #segunda camada convolucional\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 500)  # primeira camada totalmente conectada\n",
        "        self.fc2 = nn.Linear(500, 100)  # camada de saída para 100 classes (cifar-100)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#Definiçao do dispositivo de treinamento\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Transformaçoes para a normalizacao das imagens e conversao para tensores\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "#carregar dataset CIFAR-100\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "#criar dataloaders (carregar os dados em lotes)\n",
        "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "#inicializar o modelo, funcao de perda e otimizador\n",
        "model = LeNetCIFAR().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(num_epochs=10):\n",
        "  \"\"\"\n",
        "  Funcao para treinar o modelo\n",
        "  \"\"\"\n",
        "  for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}\")\n",
        "\n",
        "\n",
        "  torch.save(model.state_dict(), 'lenet_cifar100.pth')\n",
        "  print(\"Modelo salvo como 'lenet_cifar100.pth'.\")\n",
        "\n",
        "train_model(num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWWF9YRj5Bfl"
      },
      "source": [
        "***Depois que terminar a execução, já treinamos a Lenet (podem verificar que ela fica salva em um 'lenet_cifar100.pth')!! ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkhlL9fFQ8F6"
      },
      "source": [
        "## 2. Codigo para extração de atributos a partir do modelo pré-treinado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJJ7eR0W5yyz"
      },
      "source": [
        "### **Como é feita a extração de atributos de uma imagem:**\n",
        "\n",
        "*(aqui novamente, tem alguns conceitos mais avançados tbm, então se preocupem mais em entender o geral do que o código vai fazer e como rodar isso -> é importante que todos entendam direitinho como executar)*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGguFzEB-Y6W"
      },
      "source": [
        "### *(Explicação geral do funcionamento do codigo):*\n",
        "\n",
        "Primeiro é realizado o pré-processamento da imagem, que basicamente a gente vai ajusatr ela para o formato esperado pela rede (é por isso que tem os passos redimensionamento -> conversao para tensor -> normalização)\n",
        "\n",
        "Daí passa pela rede Lenet, e a imagem vai percorrer as camadas da rede até a penultima camada fc1 (aqui a gente para em fc1 porque essa camada contém os atributos extraídos da imagem. fc2 faz a classificação final, e isso não é o nosso obejtivo).\n",
        "\n",
        "A saída é uma sequência de números (tensor), que representa as características extraídas da imagem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEwq0aUY5ObF"
      },
      "source": [
        "### Aqui são exemplos de 2 imagens onde será feita a extração de atributos pelo arquivo da Lenet que a gente acabou de treinar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU5X6K5M_kLq"
      },
      "source": [
        "\n",
        "**Primeiro, a gente precisa carregar a imagem do drive (no lado esquerdo do colab, tem uma guia, vocês vão em arquivos e fazem o upload da imagem)=> isso todos vão ter que fazer.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXPFSf6xRDyh"
      },
      "source": [
        "exemplo 1 (/content/Lesao_Benigna_T2_72.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zCFS10QGDXR7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# Definição da arquitetura da rede Lenet configurada para extraçao de atributos\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)  #primeira camada convolucional\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #camada de pooling\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5) #segunda camada convolucional\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 500) #penultima camada (onde vai ser feita a extracao de atributos)\n",
        "        self.fc2 = nn.Linear(500, 100) # camada de saida com 100 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# pre processamento da imagem para torna-la compativel com a Lenet\n",
        "def preprocessamento_imagem(image_path):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  # redimensiona imagem para 32x32\n",
        "        transforms.ToTensor(),  # converte a imagem em tensor\n",
        "        transforms.Normalize((0.5,0.5, 0.5), (0.5,0.5, 0.5)) #normalizaçao\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0) #\n",
        "    return image\n",
        "\n",
        "#Funçao para extrair atributos\n",
        "def extrair_atributos_img(image_path, model):\n",
        "\n",
        "    input_image = preprocessamento_imagem(image_path).to(device)\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        # Passar pela conv1, conv2 e obter a penúltima camada\n",
        "        x = model.pool(torch.relu(model.conv1(input_image)))\n",
        "        x = model.pool(torch.relu(model.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        features = torch.relu(model.fc1(x))  # extrair os atributos da penúltima camada\n",
        "    return features\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # instanciar a LeNet e carregar os pesos pre-treinados\n",
        "    model = LeNet().to(device)\n",
        "    model.load_state_dict(torch.load('lenet_cifar100.pth'))  # carregar o modelo treinado\n",
        "\n",
        "    # Caminho para a imagem\n",
        "    image_path = '/content/Lesao_Benigna_T2_72.jpg'  #copiar o caminho da imagem aqui\n",
        "\n",
        "    # Extrair os atributos\n",
        "    features = extrair_atributos_img(image_path, model)\n",
        "    print(f\"Atributos extraídos: {features}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_dNI8V-Rwnv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrIh75kBR0gA"
      },
      "source": [
        "exemplo 2 (/content/Lesao_Benigna_T2_71.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VZVN9UwYQc13"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# Definição da arquitetura da rede Lenet configurada para extraçao de atributos\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)  #primeira camada convolucional\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #camada de pooling\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5) #segunda camada convolucional\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 500) #penultima camada (onde vai ser feita a extracao de atributos)\n",
        "        self.fc2 = nn.Linear(500, 100) # camada de saida com 100 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# pre processamento da imagem para torna-la compativel com a Lenet\n",
        "def preprocessamento_imagem(image_path):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  # redimensiona imagem para 32x32\n",
        "        transforms.ToTensor(),  # converte a imagem em tensor\n",
        "        transforms.Normalize((0.5,0.5, 0.5), (0.5,0.5, 0.5)) #normalizaçao\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0) #\n",
        "    return image\n",
        "\n",
        "#Funçao para extrair atributos\n",
        "def extrair_atributos_img(image_path, model):\n",
        "\n",
        "    input_image = preprocessamento_imagem(image_path).to(device)\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        # Passar pela conv1, conv2 e obter a penúltima camada\n",
        "        x = model.pool(torch.relu(model.conv1(input_image)))\n",
        "        x = model.pool(torch.relu(model.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        features = torch.relu(model.fc1(x))  # extrair os atributos da penúltima camada\n",
        "    return features\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # instanciar a LeNet e carregar os pesos pre-treinados\n",
        "    model = LeNet().to(device)\n",
        "    model.load_state_dict(torch.load('lenet_cifar100.pth'))  # carregar o modelo treinado\n",
        "\n",
        "    # Caminho para a imagem\n",
        "    image_path = '/content/Lesao_Benigna_T2_71.jpg'  #copiar o caminho da imagem aqui\n",
        "\n",
        "    # Extrair os atributos\n",
        "    features = extrair_atributos_img(image_path, model)\n",
        "    print(f\"Atributos extraídos: {features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EXTRAÇÃO DOS ATRIBUTOS DE LESÃO MALIGNA**"
      ],
      "metadata": {
        "id": "SMk06ZTBgjrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f5Osi7Ybzipw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTYFuZvIoOKj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import arff\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/LESAO_MALIGNA\"\n",
        "\n",
        "\n",
        "# Definição da arquitetura da rede Lenet configurada para extraçao de atributos\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)  #primeira camada convolucional\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #camada de pooling\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5) #segunda camada convolucional\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 500) #penultima camada (onde vai ser feita a extracao de atributos)\n",
        "        self.fc2 = nn.Linear(500, 100) # camada de saida com 100 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# pre processamento da imagem para torna-la compativel com a Lenet\n",
        "def preprocessamento_imagem(image_path):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  # redimensiona imagem para 32x32\n",
        "        transforms.ToTensor(),  # converte a imagem em tensor\n",
        "        transforms.Normalize((0.5,0.5, 0.5), (0.5,0.5, 0.5)) #normalizaçao\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0) #\n",
        "    return image\n",
        "\n",
        "#Funçao para extrair atributos\n",
        "def extrair_atributos_img(image_path, model):\n",
        "\n",
        "    input_image = preprocessamento_imagem(image_path).to(device)\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        # Passar pela conv1, conv2 e obter a penúltima camada\n",
        "        x = model.pool(torch.relu(model.conv1(input_image)))\n",
        "        x = model.pool(torch.relu(model.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        features = torch.relu(model.fc1(x))  # extrair os atributos da penúltima camada\n",
        "    return features.squeeze().cpu().numpy().tolist()  # Converter para lista e retornar\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # instanciar a LeNet e carregar os pesos pre-treinados\n",
        "    model = LeNet().to(device)\n",
        "    model.load_state_dict(torch.load('lenet_cifar100.pth'))  # carregar o modelo treinado\n",
        "\n",
        "   #criar dataset ARFF\n",
        "    dataset = {\n",
        "    'description': 'Atributos extraídos_LESAO MALIGNA',\n",
        "    'relation': 'Termografia_LESAO_MALIGNA_Atributos',\n",
        "    'attributes': [('attr' + str(i), 'REAL') for i in range(500)] + [('class', 'STRING')],\n",
        "    'data': []\n",
        "    }\n",
        "\n",
        "# Processar todas as imagens na pasta\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        atributos = extrair_atributos_img(image_path, model)\n",
        "        dataset['data'].append(atributos + [filename])  # Adiciona nome da imagem como rótulo\n",
        "\n",
        "# Salvar em arquivo ARFF\n",
        "output_file = \"/content/drive/MyDrive/LESAO_MALIGNA/atributos_extracao_LESAO_MALIGNA.arff\"\n",
        "with open(output_file, 'w') as f:\n",
        "    arff.dump(dataset, f)\n",
        "\n",
        "print(f\"Atributos salvos em {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EXTRAÇÃO DOS ATRIBUTOS COM TODAS AS CLASSES**"
      ],
      "metadata": {
        "id": "dYF8GZZ6z64e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import arff\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/TERMOGRAFIA_MAMA_IMAGENS\"\n",
        "\n",
        "\n",
        "# Definição da arquitetura da rede Lenet configurada para extraçao de atributos\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)  #primeira camada convolucional\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #camada de pooling\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5) #segunda camada convolucional\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 500) #penultima camada (onde vai ser feita a extracao de atributos)\n",
        "        self.fc2 = nn.Linear(500, 100) # camada de saida com 100 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# pre processamento da imagem para torna-la compativel com a Lenet\n",
        "def preprocessamento_imagem(image_path):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  # redimensiona imagem para 32x32\n",
        "        transforms.ToTensor(),  # converte a imagem em tensor\n",
        "        transforms.Normalize((0.5,0.5, 0.5), (0.5,0.5, 0.5)) #normalizaçao\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0) #\n",
        "    return image\n",
        "\n",
        "#Funçao para extrair atributos\n",
        "def extrair_atributos_img(image_path, model):\n",
        "\n",
        "    input_image = preprocessamento_imagem(image_path).to(device)\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        # Passar pela conv1, conv2 e obter a penúltima camada\n",
        "        x = model.pool(torch.relu(model.conv1(input_image)))\n",
        "        x = model.pool(torch.relu(model.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        features = torch.relu(model.fc1(x))  # extrair os atributos da penúltima camada\n",
        "    return features.squeeze().cpu().numpy().tolist()  # Converter para lista e retornar\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # instanciar a LeNet e carregar os pesos pre-treinados\n",
        "    model = LeNet().to(device)\n",
        "    model.load_state_dict(torch.load('lenet_cifar100.pth'))  # carregar o modelo treinado\n",
        "\n",
        "   #criar dataset ARFF\n",
        "    dataset = {\n",
        "    'description': 'Atributos extraídos_TERMOGRAFIA',\n",
        "    'relation': 'Termografia_Atributos',\n",
        "    'attributes': [('attr' + str(i), 'REAL') for i in range(500)] + [('class', 'STRING')],\n",
        "    'data': []\n",
        "    }\n",
        "\n",
        "# Processar todas as imagens na pasta\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        atributos = extrair_atributos_img(image_path, model)\n",
        "        dataset['data'].append(atributos + [filename])  # Adiciona nome da imagem como rótulo\n",
        "\n",
        "# Salvar em arquivo ARFF\n",
        "output_file = \"/content/drive/MyDrive/TERMOGRAFIA_MAMA_IMAGENS/atributos_extracao_TERMOGRAFIA.arff\"\n",
        "with open(output_file, 'w') as f:\n",
        "    arff.dump(dataset, f)\n",
        "\n",
        "print(f\"Atributos salvos em {output_file}\")"
      ],
      "metadata": {
        "id": "hQFKCPsSz_Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste com base mama.zip"
      ],
      "metadata": {
        "id": "_Qub3uo902NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminhos utilizados\n",
        "caminho_zip = 'mama.zip'\n",
        "destino = 'mama_extraida'\n",
        "\n",
        "# Função para extrair o arquivo ZIP\n",
        "def extrair_zip(caminho_zip : str, destino : str):\n",
        "    \"\"\"\n",
        "    Parametros:\n",
        "        input:\n",
        "        caminho_zip [str]: Caminho do arquivo ZIP.\n",
        "        destino [str]: Caminho para a pasta de destino.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(file=caminho_zip, mode='r') as zip_ref:\n",
        "        zip_ref.extractall(destino)\n",
        "\n",
        "# Processo de extração e preparação dos dados\n",
        "extrair_zip(caminho_zip, destino)\n",
        "imagens, rotulos = carregar_imagens(destino)"
      ],
      "metadata": {
        "id": "eMTtF4lK1Ds9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import arff\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/TERMOGRAFIA_MAMA_IMAGENS\"\n",
        "\n",
        "\n",
        "# Definição da arquitetura da rede Lenet configurada para extraçao de atributos\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)  #primeira camada convolucional\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #camada de pooling\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5) #segunda camada convolucional\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 500) #penultima camada (onde vai ser feita a extracao de atributos)\n",
        "        self.fc2 = nn.Linear(500, 100) # camada de saida com 100 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# pre processamento da imagem para torna-la compativel com a Lenet\n",
        "def preprocessamento_imagem(image_path):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  # redimensiona imagem para 32x32\n",
        "        transforms.ToTensor(),  # converte a imagem em tensor\n",
        "        transforms.Normalize((0.5,0.5, 0.5), (0.5,0.5, 0.5)) #normalizaçao\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0) #\n",
        "    return image\n",
        "\n",
        "#Funçao para extrair atributos\n",
        "def extrair_atributos_img(image_path, model):\n",
        "\n",
        "    input_image = preprocessamento_imagem(image_path).to(device)\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        # Passar pela conv1, conv2 e obter a penúltima camada\n",
        "        x = model.pool(torch.relu(model.conv1(input_image)))\n",
        "        x = model.pool(torch.relu(model.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        features = torch.relu(model.fc1(x))  # extrair os atributos da penúltima camada\n",
        "    return features.squeeze().cpu().numpy().tolist()  # Converter para lista e retornar\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # instanciar a LeNet e carregar os pesos pre-treinados\n",
        "    model = LeNet().to(device)\n",
        "    model.load_state_dict(torch.load('lenet_cifar100.pth'))  # carregar o modelo treinado\n",
        "\n",
        "   #criar dataset ARFF\n",
        "    dataset = {\n",
        "    'description': 'Atributos extraídos_TERMOGRAFIA',\n",
        "    'relation': 'Termografia_Atributos',\n",
        "    'attributes': [('attr' + str(i), 'REAL') for i in range(500)] + [('class', 'STRING')],\n",
        "    'data': []\n",
        "    }\n",
        "\n",
        "# Processar todas as imagens na pasta\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        atributos = extrair_atributos_img(image_path, model)\n",
        "        dataset['data'].append(atributos + [filename])  # Adiciona nome da imagem como rótulo\n",
        "\n",
        "# Salvar em arquivo ARFF\n",
        "output_file = \"/content/drive/MyDrive/TERMOGRAFIA_MAMA_IMAGENS/atributos_extracao_TERMOGRAFIA.arff\"\n",
        "with open(output_file, 'w') as f:\n",
        "    arff.dump(dataset, f)\n",
        "\n",
        "print(f\"Atributos salvos em {output_file}\")"
      ],
      "metadata": {
        "id": "KDoRtyRD0ulU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Salvar em formato CSV\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import csv\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/TERMOGRAFIA_MAMA_IMAGENS\"\n",
        "\n",
        "\n",
        "# Definição da arquitetura da rede Lenet configurada para extraçao de atributos\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)  #primeira camada convolucional\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #camada de pooling\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5) #segunda camada convolucional\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 500) #penultima camada (onde vai ser feita a extracao de atributos)\n",
        "        self.fc2 = nn.Linear(500, 100) # camada de saida com 100 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# pre processamento da imagem para torna-la compativel com a Lenet\n",
        "def preprocessamento_imagem(image_path):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  # redimensiona imagem para 32x32\n",
        "        transforms.ToTensor(),  # converte a imagem em tensor\n",
        "        transforms.Normalize((0.5,0.5, 0.5), (0.5,0.5, 0.5)) #normalizaçao\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0) #\n",
        "    return image\n",
        "\n",
        "#Funçao para extrair atributos\n",
        "def extrair_atributos_img(image_path, model):\n",
        "\n",
        "    input_image = preprocessamento_imagem(image_path).to(device)\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        # Passar pela conv1, conv2 e obter a penúltima camada\n",
        "        x = model.pool(torch.relu(model.conv1(input_image)))\n",
        "        x = model.pool(torch.relu(model.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 5)\n",
        "        features = torch.relu(model.fc1(x))  # extrair os atributos da penúltima camada\n",
        "    return features.squeeze().cpu().numpy().tolist()  # Converter para lista e retornar\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # instanciar a LeNet e carregar os pesos pre-treinados\n",
        "    model = LeNet().to(device)\n",
        "    model.load_state_dict(torch.load('/content/lenet_cifar100.pth'))  # carregar o modelo treinado\n",
        "\n",
        "   #caminho do csv de saida\n",
        "    output_csv = \"/content/drive/MyDrive/TERMOGRAFIA_MAMA_IMAGENS/atributos_extracao_TERMOGRAFIA.csv\"\n",
        "\n",
        "   #cabeçalhos\n",
        "    headers = ['attr' + str(i) for i in range(500)] + ['class']\n",
        "\n",
        "\n",
        "    # Escreve os dados\n",
        "    with open(output_csv, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(headers)\n",
        "\n",
        "        for filename in os.listdir(image_folder):\n",
        "            if filename.lower().endswith(('.jpg', '.png')):\n",
        "                image_path = os.path.join(image_folder, filename)\n",
        "                atributos = extrair_atributos_img(image_path, model)\n",
        "                writer.writerow(atributos + [filename])\n",
        "\n",
        "    print(f\"Atributos salvos com sucesso em: {output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DcMD9UM3J08D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}